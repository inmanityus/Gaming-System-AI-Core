# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: ai_integration.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'ai_integration.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import struct_pb2 as google_dot_protobuf_dot_struct__pb2
from google.protobuf import wrappers_pb2 as google_dot_protobuf_dot_wrappers__pb2
import common_pb2 as common__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x14\x61i_integration.proto\x12\x11\x61i_integration.v1\x1a\x1cgoogle/protobuf/struct.proto\x1a\x1egoogle/protobuf/wrappers.proto\x1a\x0c\x63ommon.proto\"\xac\x01\n\x0b\x43hatMessage\x12\x31\n\x04role\x18\x01 \x01(\x0e\x32#.ai_integration.v1.ChatMessage.Role\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\"K\n\x04Role\x12\x14\n\x10ROLE_UNSPECIFIED\x10\x00\x12\n\n\x06SYSTEM\x10\x01\x12\x08\n\x04USER\x10\x02\x12\r\n\tASSISTANT\x10\x03\x12\x08\n\x04TOOL\x10\x04\"@\n\x0c\x43hatMessages\x12\x30\n\x08messages\x18\x01 \x03(\x0b\x32\x1e.ai_integration.v1.ChatMessage\"\x80\x03\n\x14GenerationParameters\x12\x31\n\x0btemperature\x18\x01 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue\x12+\n\x05top_p\x18\x02 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue\x12\x30\n\nmax_tokens\x18\x03 \x01(\x0b\x32\x1c.google.protobuf.UInt32Value\x12+\n\x05top_k\x18\x04 \x01(\x0b\x32\x1c.google.protobuf.UInt32Value\x12\x36\n\x10presence_penalty\x18\x05 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue\x12\x37\n\x11\x66requency_penalty\x18\x06 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue\x12\x0c\n\x04stop\x18\x07 \x03(\t\x12*\n\x06stream\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.BoolValue\"\xfe\x01\n\x13LLMInferenceRequest\x12\x1d\n\x04meta\x18\x01 \x01(\x0b\x32\x0f.common.v1.Meta\x12\x10\n\x08model_id\x18\x02 \x01(\t\x12\x10\n\x06prompt\x18\x03 \x01(\tH\x00\x12\x38\n\rchat_messages\x18\x04 \x01(\x0b\x32\x1f.ai_integration.v1.ChatMessagesH\x00\x12\x37\n\x06params\x18\x05 \x01(\x0b\x32\'.ai_integration.v1.GenerationParameters\x12(\n\x07\x63ontext\x18\x06 \x01(\x0b\x32\x17.google.protobuf.StructB\x07\n\x05input\"\x85\x02\n\x14LLMInferenceResponse\x12\x1d\n\x04meta\x18\x01 \x01(\x0b\x32\x0f.common.v1.Meta\x12\x15\n\rgeneration_id\x18\x02 \x01(\t\x12\x15\n\x0boutput_text\x18\x03 \x01(\tH\x00\x12\x38\n\rchat_messages\x18\x04 \x01(\x0b\x32\x1f.ai_integration.v1.ChatMessagesH\x00\x12\x15\n\rfinish_reason\x18\x05 \x01(\t\x12$\n\x05usage\x18\x06 \x01(\x0b\x32\x15.common.v1.TokenUsage\x12\x1f\n\x05\x65rror\x18\x07 \x01(\x0b\x32\x10.common.v1.ErrorB\x08\n\x06output\"\xa4\x02\n\x0eLLMStreamChunk\x12\x1d\n\x04meta\x18\x01 \x01(\x0b\x32\x0f.common.v1.Meta\x12\x15\n\rgeneration_id\x18\x02 \x01(\t\x12\r\n\x05index\x18\x03 \x01(\r\x12\x10\n\x08is_final\x18\x04 \x01(\x08\x12\x1b\n\x11output_text_delta\x18\x05 \x01(\tH\x00\x12\x37\n\rmessage_delta\x18\x06 \x01(\x0b\x32\x1e.ai_integration.v1.ChatMessageH\x00\x12\x15\n\rfinish_reason\x18\x07 \x01(\t\x12$\n\x05usage\x18\x08 \x01(\x0b\x32\x15.common.v1.TokenUsage\x12\x1f\n\x05\x65rror\x18\t \x01(\x0b\x32\x10.common.v1.ErrorB\x07\n\x05\x64\x65ltab\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'ai_integration_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_CHATMESSAGE']._serialized_start=120
  _globals['_CHATMESSAGE']._serialized_end=292
  _globals['_CHATMESSAGE_ROLE']._serialized_start=217
  _globals['_CHATMESSAGE_ROLE']._serialized_end=292
  _globals['_CHATMESSAGES']._serialized_start=294
  _globals['_CHATMESSAGES']._serialized_end=358
  _globals['_GENERATIONPARAMETERS']._serialized_start=361
  _globals['_GENERATIONPARAMETERS']._serialized_end=745
  _globals['_LLMINFERENCEREQUEST']._serialized_start=748
  _globals['_LLMINFERENCEREQUEST']._serialized_end=1002
  _globals['_LLMINFERENCERESPONSE']._serialized_start=1005
  _globals['_LLMINFERENCERESPONSE']._serialized_end=1266
  _globals['_LLMSTREAMCHUNK']._serialized_start=1269
  _globals['_LLMSTREAMCHUNK']._serialized_end=1561
# @@protoc_insertion_point(module_scope)
