# PRD Workflow Rules

## Overview
This rule enables Cursor AI to execute the `build_out_prd` workflow, providing comprehensive PRD analysis and solution building capabilities using Docker containers, best practices, and automated testing.

## Workflow Definition
When the user requests "Build The Attached PRD" or "build_out_prd", the AI must:

### Step 1: Research Docker Best Practices Using Exa MCP
1. **Search Docker Security**:
   ```
   Query: "Docker container best practices Linux development production security deployment"
   ```

2. **Search Docker Architecture**:
   ```
   Query: "Docker multi-stage builds security hardening production deployment best practices"
   ```

3. **Search Container Orchestration**:
   ```
   Query: "Docker Compose production deployment microservices architecture best practices"
   ```

**Important**: Analyze research results and apply Docker best practices to container setup.

### Step 2: Create Secure Linux Docker Container
Create a production-ready Linux Docker container with:
- Multi-stage builds for optimization
- Non-root user for security
- Minimal base images
- Security hardening
- Development and production configurations

#### Dockerfile Templates
```dockerfile
# Frontend Dockerfile
FROM node:18-alpine AS base
RUN apk add --no-cache libc6-compat
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM node:18-alpine AS production
WORKDIR /app
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001
COPY --from=base --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=base --chown=nextjs:nodejs /app/.next/static ./.next/static
COPY --from=base --chown=nextjs:nodejs /app/public ./public
USER nextjs
EXPOSE 3000
CMD ["node", "server.js"]
```

```dockerfile
# Backend Dockerfile
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM node:18-alpine AS production
WORKDIR /app
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001
COPY --from=base --chown=nodejs:nodejs /app/dist ./dist
COPY --from=base --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=base --chown=nodejs:nodejs /app/package*.json ./
USER nodejs
EXPOSE 5000
CMD ["node", "dist/index.js"]
```

#### Docker Compose Configuration
```yaml
version: '3.8'
services:
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - REACT_APP_API_URL=http://backend:5000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    networks:
      - app-network

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "5000:5000"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://user:password@database:5432/appdb
    volumes:
      - ./backend:/app
      - /app/node_modules
    depends_on:
      - database
    networks:
      - app-network

  database:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=appdb
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app-network

volumes:
  postgres_data:

networks:
  app-network:
    driver: bridge
```

### Step 3: Analyze PRD and Determine Technology Stack
Read the PRD document thoroughly and:
- Identify specified platforms and technologies
- If none specified, analyze requirements to determine optimal stack
- Research best practices for the selected technologies
- Create technology selection rationale

#### PRD Analysis Framework
```javascript
class PRDAnalyzer {
  analyzePRD(prdContent) {
    return {
      projectType: this.determineProjectType(prdContent),
      targetPlatforms: this.extractTargetPlatforms(prdContent),
      specifiedTechnologies: this.extractSpecifiedTechnologies(prdContent),
      requirements: this.extractRequirements(prdContent),
      userStories: this.extractUserStories(prdContent),
      technicalConstraints: this.extractTechnicalConstraints(prdContent)
    };
  }
  
  determineProjectType(prdContent) {
    const types = {
      'web-application': /web|website|browser/i,
      'mobile-app': /mobile|app|ios|android/i,
      'desktop-app': /desktop|windows|mac|linux/i,
      'api-service': /api|service|microservice/i,
      'e-commerce': /ecommerce|shop|store|payment/i,
      'cms': /content|cms|blog|news/i,
      'dashboard': /dashboard|admin|analytics/i
    };
    
    for (const [type, pattern] of Object.entries(types)) {
      if (pattern.test(prdContent)) {
        return type;
      }
    }
    
    return 'web-application'; // Default
  }
  
  extractTargetPlatforms(prdContent) {
    const platforms = [];
    if (/web|browser/i.test(prdContent)) platforms.push('web');
    if (/mobile|ios|android/i.test(prdContent)) platforms.push('mobile');
    if (/desktop|windows|mac|linux/i.test(prdContent)) platforms.push('desktop');
    return platforms.length > 0 ? platforms : ['web'];
  }
}
```

### Step 4: Research Best Practices and Security Measures
Use Exa MCP to research:
- Best practices for selected technologies
- Security measures and hardening techniques
- Performance optimization strategies
- Deployment and scaling considerations

#### Research Queries
```javascript
const researchQueries = [
  `${selectedFrontend} best practices security performance 2024`,
  `${selectedBackend} security hardening authentication authorization`,
  `${selectedDatabase} security best practices data protection`,
  `microservices architecture patterns ${selectedStack} deployment`,
  `container security docker ${selectedStack} production`
];
```

### Step 5: Design Solution Architecture
Act as a senior expert architect and engineer to:
- Design the overall solution architecture
- Create component diagrams and relationships
- Define API contracts and data models
- Plan for scalability and maintainability
- Ensure security by design

#### Architecture Design Template
```javascript
class SolutionArchitect {
  designArchitecture(prdAnalysis, technologyStack) {
    return {
      overallArchitecture: this.designOverallArchitecture(prdAnalysis),
      componentDiagram: this.createComponentDiagram(prdAnalysis),
      apiDesign: this.designAPIs(prdAnalysis),
      dataModel: this.designDataModel(prdAnalysis),
      securityArchitecture: this.designSecurityArchitecture(prdAnalysis),
      deploymentArchitecture: this.designDeploymentArchitecture(prdAnalysis)
    };
  }
  
  designOverallArchitecture(analysis) {
    const patterns = {
      'web-application': 'MVC with API Gateway',
      'mobile-app': 'Backend for Frontend (BFF)',
      'e-commerce': 'Microservices with Event Sourcing',
      'dashboard': 'SPA with RESTful APIs',
      'cms': 'Headless CMS with CDN'
    };
    
    return {
      pattern: patterns[analysis.projectType] || 'Layered Architecture',
      layers: ['Presentation', 'Business Logic', 'Data Access', 'Data Storage'],
      components: this.identifyComponents(analysis),
      communication: this.designCommunicationPatterns(analysis)
    };
  }
}
```

### Step 6: Build Out Complete Solution
Create:
- Frontend project with modern framework
- Backend API services
- Database schema and migrations
- Authentication and authorization
- API documentation
- Environment configurations

#### Authentication and Authorization Setup
```javascript
class AuthService {
  constructor() {
    this.jwtSecret = process.env.JWT_SECRET;
    this.bcryptRounds = 12;
  }
  
  async hashPassword(password) {
    return await bcrypt.hash(password, this.bcryptRounds);
  }
  
  async verifyPassword(password, hash) {
    return await bcrypt.compare(password, hash);
  }
  
  generateToken(user) {
    return jwt.sign(
      { 
        userId: user.id, 
        email: user.email, 
        role: user.role 
      },
      this.jwtSecret,
      { expiresIn: '24h' }
    );
  }
  
  verifyToken(token) {
    return jwt.verify(token, this.jwtSecret);
  }
}

const requireAuth = (req, res, next) => {
  const token = req.headers.authorization?.split(' ')[1];
  
  if (!token) {
    return res.status(401).json({ error: 'No token provided' });
  }
  
  try {
    const decoded = authService.verifyToken(token);
    req.user = decoded;
    next();
  } catch (error) {
    return res.status(401).json({ error: 'Invalid token' });
  }
};
```

#### Project Structure Generation
```bash
# Create project structure
mkdir -p {frontend,backend,database,docs,scripts,deployments}
mkdir -p frontend/{src,public,components,pages,services,utils}
mkdir -p backend/{src,routes,models,middleware,services,utils}
mkdir -p database/{migrations,seeds,schemas}
mkdir -p docs/{api,architecture,deployment}
mkdir -p scripts/{build,deploy,test}
mkdir -p deployments/{docker,kubernetes,terraform}
```

### Step 7: Database Setup and Schema
Create:
- Database schema based on PRD requirements
- Migration scripts
- Seed data
- Indexes and constraints
- Backup and recovery procedures

#### Database Schema Template
```sql
-- Users table
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    first_name VARCHAR(100) NOT NULL,
    last_name VARCHAR(100) NOT NULL,
    role VARCHAR(50) DEFAULT 'user',
    is_active BOOLEAN DEFAULT true,
    email_verified BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_role ON users(role);
CREATE INDEX idx_users_active ON users(is_active);

-- Create updated_at trigger
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### Step 8: Integration with Testing Workflows
Run the comprehensive testing workflow:
- Execute unit, functional, and system tests
- Fix any issues found during testing
- Ensure all tests pass before proceeding

#### Testing Integration
```bash
# Run comprehensive testing workflow
echo "Starting comprehensive testing workflow..."
./scripts/run-comprehensive-tests.sh

# Check test results
if [ $? -eq 0 ]; then
    echo "All tests passed successfully!"
else
    echo "Tests failed. Fixing issues..."
    # AI will analyze and fix test failures
fi
```

### Step 9: Visual Testing Integration
Run the visual testing workflow:
- Check for global stylesheet
- If stylesheet not found, ask user to provide it
- Ensure frontend looks as expected
- Fix any visual issues

#### Visual Testing Integration
```bash
# Check for global stylesheet
if [ ! -f "frontend/src/styles/global.css" ]; then
    echo "Global stylesheet not found. Please provide the stylesheet."
    read -p "Please provide the path to your global stylesheet: " stylesheet_path
    if [ -f "$stylesheet_path" ]; then
        cp "$stylesheet_path" "frontend/src/styles/global.css"
        echo "Global stylesheet copied successfully."
    else
        echo "Stylesheet not found. Creating default stylesheet."
        # Create default stylesheet
    fi
fi

# Run visual testing workflow
echo "Starting visual testing workflow..."
./scripts/run-visual-tests.sh
```

### Step 10: Final Validation and Documentation
Validate all components work together:
- Generate comprehensive documentation
- Create deployment guides
- Ensure production readiness
- Generate final report

#### Final Validation
```bash
# Build all projects
echo "Building all projects..."
docker-compose build

# Start all services
echo "Starting all services..."
docker-compose up -d

# Wait for services to be ready
echo "Waiting for services to be ready..."
sleep 30

# Run health checks
echo "Running health checks..."
curl -f http://localhost:3000/health || exit 1
curl -f http://localhost:5000/health || exit 1

# Run integration tests
echo "Running integration tests..."
npm run test:integration

echo "All validations passed successfully!"
```

## Key Principles
1. **Security First**: All components must follow security best practices
2. **Production Ready**: Everything must be deployable to production
3. **Independent Deployment**: Each component can be deployed separately
4. **Comprehensive Testing**: All code must be thoroughly tested
5. **Documentation**: Complete documentation for all components
6. **Best Practices**: Follow industry best practices throughout

## Success Criteria
The workflow is complete when:
- ✅ Docker container is created with security best practices
- ✅ PRD is analyzed and technology stack is selected
- ✅ Complete solution architecture is designed
- ✅ All components are built and functional
- ✅ Comprehensive tests pass
- ✅ Visual tests pass
- ✅ All components can run independently
- ✅ Production deployment is ready

## Error Handling
When issues occur:
1. Log detailed error information
2. Attempt automatic fixes where possible
3. Provide clear error messages
4. Continue with remaining components
5. Generate error report for manual review

## Integration with Existing Workflows
This PRD workflow integrates with:
- Comprehensive testing workflows
- Visual testing workflows
- AWS deployment workflows
- Mobile app deployment workflows

## Command Integration
The workflow is tied to the command: **"Build The Attached PRD"**

When this command is used, the AI will:
1. Look for attached PRD documents
2. Execute the complete workflow automatically
3. Build the entire solution based on PRD requirements
4. Run all tests and validations
5. Provide comprehensive documentation

The AI must ensure all deployed applications meet quality and security standards before deployment completion.