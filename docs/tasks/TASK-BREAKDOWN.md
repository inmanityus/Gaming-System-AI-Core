# The Body Broker - Complete Implementation Task Breakdown
**Date**: January 29, 2025  
**Status**: Production-Ready Task List  
**Enforcement**: ALL rules in `/all-rules` are MANDATORY for every task

---

## ðŸš¨ CRITICAL RULES - MANDATORY FOR ALL TASKS

### **NO FAKE/MOCK CODE - MANDATORY**
- âŒ **NEVER** create mock interfaces, stubs, or fake implementations
- âŒ **NEVER** use test doubles that don't test real functionality
- âœ… **ALWAYS** implement real, working code that actually functions
- âœ… **ALWAYS** test against real services, real databases, real APIs
- âœ… **ONLY** exception: Hardware simulators for custom hardware deployments

### **ALL-RULES COMPLIANCE - MANDATORY**
- âœ… Memory consolidation at task start (MANDATORY)
- âœ… Comprehensive testing after every task (MANDATORY)
- âœ… 45-minute milestone writing after task completion (MANDATORY)
- âœ… Continuity - never stop working between tasks (MANDATORY)
- âœ… Timer protection always active (MANDATORY)
- âœ… Work visibility in session window (MANDATORY)

### **CENTRAL LOG FILE LOCATION**
**Log File**: `.cursor/logs/session-{timestamp}.log`
**Status File**: `.cursor/memory/active/TASK-STATUS.md`
**Manager Log**: `.cursor/logs/manager.log`

---

## PHASE 1: FOUNDATION & INFRASTRUCTURE

### Task 1.1: Core Data Models & Schemas
**Task ID:** TBB-001  
**Dependencies:** None  
**Description:**  
Implement all database schemas and data models for game state, player data, story elements, and transactions. Create actual PostgreSQL schemas with proper indexes, constraints, and relationships.

**Deliverables:**
- `models/player.py` - Player entity with stats, inventory, augmentations
- `models/game_state.py` - Active game session state model
- `models/story_node.py` - Story progression and narrative state
- `models/transaction.py` - Payment and economy tracking
- `models/world_state.py` - World simulation state (Story Teller)
- `models/npc.py` - NPC entities with personality vectors
- `models/faction.py` - Faction relationships and power dynamics
- `models/augmentation.py` - Body modification catalog
- `database/migrations/001_initial_schema.sql` - Database migration scripts
- `schemas/validation.py` - Pydantic/validation schemas

**Acceptance Criteria:**
- All models can be instantiated and persisted to PostgreSQL database
- Foreign key relationships work correctly
- Indexes improve query performance (verified via EXPLAIN ANALYZE)
- Models support serialization to/from JSON
- Migration scripts run successfully on fresh database
- **REAL TEST**: Connect to PostgreSQL, run migrations, create records, verify persistence

---

### Task 1.2: State Management Service Core
**Task ID:** TBB-002  
**Dependencies:** TBB-001  
**Description:**  
Build the State Management service with Redis Cluster for caching and PostgreSQL for persistence. Implement CRUD operations, atomic state updates, and conflict resolution. Use REAL Redis and PostgreSQL connections.

**Deliverables:**
- `services/state_manager/server.py` - FastAPI service
- `services/state_manager/state_operations.py` - CRUD operations
- `services/state_manager/cache_layer.py` - Redis Cluster caching implementation
- `services/state_manager/conflict_resolver.py` - Optimistic locking/versioning
- `services/state_manager/api_routes.py` - RESTful endpoints
- `services/state_manager/connection_pool.py` - Connection pooling (200 gRPC, 35-50 PostgreSQL, 100 Redis)
- `docker-compose.state.yml` - Service deployment config with REAL Redis Cluster

**Acceptance Criteria:**
- Can create, read, update, delete game states in REAL PostgreSQL
- Concurrent updates handled with proper versioning
- Cache hit rate >80% for read operations (tested against REAL Redis)
- State persistence survives service restart
- API returns proper HTTP status codes and error messages
- **REAL TEST**: Run service, connect to Redis Cluster, perform operations, verify cache hit rates

---

### Task 1.3: Configuration & Settings Service
**Task ID:** TBB-003  
**Dependencies:** TBB-001  
**Description:**  
Implement the Settings service for managing game configuration, player preferences, difficulty settings, and feature flags. Include hot-reloading capabilities with REAL database persistence.

**Deliverables:**
- `services/settings/server.py` - Settings service API
- `services/settings/config_manager.py` - Configuration CRUD
- `services/settings/feature_flags.py` - Feature toggle system
- `services/settings/preference_handler.py` - User preference management
- `config/default_settings.json` - Default configuration
- `services/settings/hot_reload.py` - Live config updates
- `services/settings/tier_manager.py` - User tier management (Free/Premium/Whale)

**Acceptance Criteria:**
- Settings can be updated without service restart (REAL hot-reload)
- Feature flags toggle functionality on/off
- Player preferences persist across sessions in REAL database
- Configuration validation prevents invalid values
- Settings API accessible via REST endpoints
- **REAL TEST**: Update settings via API, verify changes persist, restart service, verify persistence

---

## PHASE 2: AI INFERENCE & MODEL SERVING

### Task 2.1: AI Inference Service - Ollama Integration
**Task ID:** TBB-004  
**Dependencies:** TBB-003  
**Description:**  
Implement AI Inference service with REAL Ollama integration. Set up model serving with vLLM, load base models, and implement LoRA adapter management. Use REAL model files and REAL inference calls.

**Deliverables:**
- `services/ai_inference/server.py` - AI service API (FastAPI)
- `services/ai_inference/ollama_client.py` - REAL Ollama API client
- `services/ai_inference/vllm_server.py` - vLLM model serving setup
- `services/ai_inference/model_manager.py` - Model loading/unloading
- `services/ai_inference/lora_manager.py` - LoRA adapter management
- `services/ai_inference/prompt_templates.py` - Engineered prompts
- `services/ai_inference/response_parser.py` - Structure extraction from LLM
- `services/ai_inference/context_builder.py` - Game context for prompts
- `services/ai_inference/rate_limiter.py` - API rate limiting (tiered)
- `services/ai_inference/streaming.py` - Response streaming implementation

**Model Setup (REAL):**
- Copy `llama3.1:8b` â†’ `story-world-gen` (for world generation)
- Copy `mistral:7b` â†’ `story-narrative` (for narrative generation)
- Copy `qwen2.5:7b` â†’ `story-events` (for event generation)
- Fine-tune each with specialized datasets

**Acceptance Criteria:**
- Successfully calls REAL Ollama API and receives responses
- Models load and serve requests (tested with REAL inference calls)
- LoRA adapters can be loaded/unloaded dynamically
- Generates contextually relevant NPC dialogue (REAL dialogue, not mocked)
- Parses structured data from responses
- Handles API errors gracefully with retries
- Respects rate limits
- **REAL TEST**: Start Ollama, load models, make inference calls, verify real responses

---

### Task 2.2: Model Fine-Tuning Pipeline
**Task ID:** TBB-005  
**Dependencies:** TBB-004  
**Description:**  
Set up model fine-tuning pipeline using REAL training data. Fine-tune models for world generation, narrative generation, and event generation using AWS SageMaker or local training infrastructure.

**Deliverables:**
- `training/data_preparation.py` - REAL data preparation scripts
- `training/world_gen_dataset.py` - World generation training data (50k samples)
- `training/narrative_dataset.py` - Narrative training data (cyberpunk/horror corpus)
- `training/event_dataset.py` - Event generation training data
- `training/train_lora.py` - LoRA fine-tuning script
- `training/train_quantization.py` - Model quantization pipeline
- `training/aws_sagemaker_pipeline.py` - SageMaker training integration
- `training/evaluation.py` - Model evaluation metrics

**Training Data Requirements:**
- REAL human-written cyberpunk/horror fiction (50k passages)
- REAL player-generated content (if available)
- REAL imperfect/emotional text samples (15k samples)
- NO synthetic or AI-generated training data

**Acceptance Criteria:**
- Models fine-tuned on REAL datasets
- Fine-tuned models improve on evaluation metrics
- LoRA adapters can be trained and deployed
- Training pipeline runs successfully on SageMaker
- Fine-tuned models pass quality benchmarks
- **REAL TEST**: Run training pipeline, verify model improvements, deploy fine-tuned model, test inference

---

### Task 2.3: AI Detection Bypass System
**Task ID:** TBB-006  
**Dependencies:** TBB-005  
**Description:**  
Implement AI detection bypass pipeline with REAL deep learning filter model. Train custom BERT-based detector and implement multi-stage humanization pipeline. Use REAL adversarial training.

**Deliverables:**
- `services/ai_inference/ai_detection_filter.py` - Custom BERT-based detector
- `services/ai_inference/humanization_pipeline.py` - Multi-stage humanization
- `services/ai_inference/stylistic_variator.py` - Stylistic variation engine
- `services/ai_inference/imperfection_layer.py` - Imperfection injection
- `services/ai_inference/adversarial_rewriter.py` - Real-time rewriting
- `training/detector_training.py` - Detector model training
- `training/adversarial_training.py` - Adversarial training loop

**Acceptance Criteria:**
- Detector model trained on REAL human/AI paired datasets
- Humanization pipeline reduces AI detection scores to <0.3
- Adversarial training improves bypass rates
- Outputs pass GPTZero, Originality.ai detection
- **REAL TEST**: Generate content, run through detector, verify human-likeness scores

---

## PHASE 3: ORCHESTRATION & 4-LAYER SYSTEM

### Task 3.1: Orchestration Service - 4-Layer Pipeline
**Task ID:** TBB-007  
**Dependencies:** TBB-004, TBB-002  
**Description:**  
Implement Orchestration service with REAL 4-layer hierarchical LLM pipeline. Layer 1 (Foundation), Layer 2 (Customization), Layer 3 (Interaction), Layer 4 (Coordination). Use REAL model calls, not mocks.

**Deliverables:**
- `services/orchestration/server.py` - Orchestration service API
- `services/orchestration/layer1_foundation.py` - Foundation layer implementation
- `services/orchestration/layer2_customization.py` - Customization layer with REAL LoRA adapters
- `services/orchestration/layer3_interaction.py` - Interaction layer (NPC dialogue)
- `services/orchestration/layer4_coordination.py` - Coordination layer (cloud LLMs: GPT-5, Claude 4.5)
- `services/orchestration/state_manager.py` - Shared state manager
- `services/orchestration/parallel_executor.py` - Parallel execution engine
- `services/orchestration/conflict_resolver.py` - Conflict resolution

**Integration Points (REAL):**
- REAL gRPC calls to AI Inference Service
- REAL API calls to cloud LLM providers (OpenAI, Anthropic)
- REAL Redis connections for state
- REAL PostgreSQL connections for persistence

**Acceptance Criteria:**
- Layer 1 generates base content (REAL procedural generation + small LLMs)
- Layer 2 customizes with REAL LoRA adapters
- Layer 3 generates REAL NPC dialogue (not mocked)
- Layer 4 coordinates with REAL cloud LLM calls
- All layers integrate with REAL services
- **REAL TEST**: Run orchestration pipeline, verify each layer calls real services, verify outputs

---

### Task 3.2: Battle Coordination System
**Task ID:** TBB-008  
**Dependencies:** TBB-007  
**Description:**  
Implement battle coordination for multi-NPC combat. Each NPC acts autonomously via their LLM, then coordinator ensures group cohesion. Use REAL LLM calls for each NPC decision.

**Deliverables:**
- `services/orchestration/battle_coordinator.py` - Battle coordination logic
- `services/orchestration/npc_decision_maker.py` - Autonomous NPC decisions
- `services/orchestration/group_tactics.py` - Pack coordination
- `services/orchestration/combat_resolution.py` - Combat outcome calculation

**Acceptance Criteria:**
- NPCs make REAL autonomous decisions via LLM calls
- Coordinator synthesizes group actions
- Combat outcomes calculated correctly
- **REAL TEST**: Simulate battle with 5 NPCs, verify each makes real LLM calls, verify coordination

---

## PHASE 4: STORY TELLER SERVICE

### Task 4.1: World Simulation Engine
**Task ID:** TBB-009  
**Dependencies:** TBB-007, TBB-002  
**Description:**  
Implement World Simulation Engine for continuous background simulation. NPCs interact independently, factions shift power, events occur when player is offline. Use REAL simulation, not statistical models only.

**Deliverables:**
- `services/story_teller/world_simulation_engine.py` - Core simulation engine
- `services/story_teller/temporal_orchestrator.py` - Multi-speed time management
- `services/story_teller/faction_simulator.py` - Faction dynamics (REAL agent simulation)
- `services/story_teller/npc_behavior_system.py` - Autonomous NPC agents
- `services/story_teller/economic_simulator.py` - Economic model
- `services/story_teller/spatial_manager.py` - Territory control
- `services/story_teller/causal_chain.py` - Action â†’ Consequence tracking

**NPC Agent System (REAL):**
- Each NPC has REAL personality vector (50-dim)
- REAL goal stack (hierarchical objectives)
- REAL episodic memory
- REAL relationship graph
- REAL LLM-based decision making per NPC

**Acceptance Criteria:**
- Simulation runs continuously when player offline
- NPCs make REAL independent decisions via LLM calls
- Faction power shifts calculated correctly
- Events propagate through causal chains
- **REAL TEST**: Run simulation for 1 game day, verify NPC interactions, verify world state changes

---

### Task 4.2: Narrative Weaver - Human-Like Narrative Generation
**Task ID:** TBB-010  
**Dependencies:** TBB-009, TBB-006  
**Description:**  
Implement Narrative Weaver that transforms simulation events into compelling, human-like narratives. Integrates AI detection bypass pipeline. Generates REAL quests, not templates.

**Deliverables:**
- `services/story_teller/narrative_weaver.py` - Narrative generation engine
- `services/story_teller/story_arc_generator.py` - Long-term plot threads
- `services/story_teller/quest_synthesizer.py` - Quest generation (REAL, unique quests)
- `services/story_teller/consequence_mapper.py` - Player actions â†’ World changes
- `services/story_teller/pacing_controller.py` - Challenge/reward rhythm
- `services/story_teller/novelty_filter.py` - Anti-repetition system
- `services/story_teller/integration.py` - Integration with AI detection bypass

**Acceptance Criteria:**
- Generates REAL, unique quests (not repeating templates)
- Narratives pass AI detection (<15% flagged)
- Quest chains maintain coherence
- Player actions influence narrative
- **REAL TEST**: Generate 100 quests, verify uniqueness, run through AI detector, verify <15% flagged

---

### Task 4.3: Event Generator - Novel Events
**Task ID:** TBB-011  
**Dependencies:** TBB-010  
**Description:**  
Implement Event Generator that creates unpredictable, contextual events. Uses 10,000+ event templates with procedural parameters. Never boring - ensures novelty via Bloom filter + Vector similarity.

**Deliverables:**
- `services/story_teller/event_generator.py` - Event generation engine
- `services/story_teller/random_seed_mixer.py` - Quantum randomness integration
- `services/story_teller/context_analyzer.py` - World context analysis
- `services/story_teller/constraint_solver.py` - World logic constraints
- `services/story_teller/novelty_enforcer.py` - Novelty checking (Bloom filter + Vector DB)
- `services/story_teller/chaos_engine.py` - Wildcard event injection
- `data/event_templates/` - 10,000+ event template definitions

**Acceptance Criteria:**
- Generates unique events that haven't been seen before
- Events respect world logic constraints
- Novelty checking prevents repetition
- Wildcard events inject unpredictability
- **REAL TEST**: Generate 1000 events, verify uniqueness, verify constraints respected

---

### Task 4.4: Story Teller Integration with Existing Services
**Task ID:** TBB-012  
**Dependencies:** TBB-009, TBB-010, TBB-011, TBB-007  
**Description:**  
Integrate Story Teller service with all existing services. Real API calls, real message bus (Kafka), real state updates. No mocked integrations.

**Deliverables:**
- `services/story_teller/orchestration_integration.py` - REAL calls to Orchestration Service
- `services/story_teller/state_integration.py` - REAL state updates to State Management
- `services/story_teller/ai_inference_integration.py` - REAL calls to AI Inference Service
- `services/story_teller/message_bus.py` - REAL Kafka integration
- `services/story_teller/redis_pubsub.py` - REAL Redis Pub/Sub for real-time updates
- `services/story_teller/game_engine_integration.py` - REAL world updates to Game Engine

**Integration Contracts (REAL):**
- gRPC calls to Orchestration Service (REAL connection pool)
- HTTP/REST calls to State Management (REAL endpoints)
- Kafka message publishing (REAL Kafka cluster)
- Redis Pub/Sub channels (REAL Redis)

**Acceptance Criteria:**
- Story Teller calls REAL Orchestration Service APIs
- World state updates persist in REAL PostgreSQL
- Events published to REAL Kafka topics
- Real-time updates via REAL Redis Pub/Sub
- **REAL TEST**: Run Story Teller, verify all service calls are real, verify messages in Kafka, verify state in PostgreSQL

---

## PHASE 5: GAME ENGINE (UNREAL ENGINE 5)

### Task 5.1: UE5 Project Setup & Core Systems
**Task ID:** TBB-013  
**Dependencies:** TBB-003  
**Description:**  
Set up Unreal Engine 5 project with core game systems. Implement dual-world system (Day/Night), basic gameplay loop, and UE5 optimization systems (World Partition, LOD, async loading).

**Deliverables:**
- `unreal/` - UE5 project directory
- `unreal/Source/BodyBroker/GameMode/BodyBrokerGameMode.h` - Game mode with day/night switching
- `unreal/Source/BodyBroker/GameMode/BodyBrokerGameMode.cpp` - REAL implementation
- `unreal/Source/BodyBroker/Systems/WorldPartitionManager.h` - World Partition integration
- `unreal/Source/BodyBroker/Systems/LODManager.h` - LOD system manager
- `unreal/Source/BodyBroker/Systems/AsyncLoader.h` - Async asset loading
- `unreal/Content/` - Game assets and Blueprints

**Acceptance Criteria:**
- UE5 project builds successfully
- Day/Night world switching works
- World Partition streams chunks correctly
- LOD system reduces polygons appropriately
- Async loading doesn't block game thread
- **REAL TEST**: Build UE5 project, run game, verify world switching, profile performance

---

### Task 5.2: AI Dialogue Integration (UE5)
**Task ID:** TBB-014  
**Dependencies:** TBB-013, TBB-004  
**Description:**  
Implement AI dialogue system integration in UE5. Make REAL HTTP/gRPC calls to AI Inference Service. Handle streaming responses, non-blocking async requests.

**Deliverables:**
- `unreal/Source/BodyBroker/Dialogue/UDialogueManager.h` - Dialogue manager class
- `unreal/Source/BodyBroker/Dialogue/UDialogueManager.cpp` - REAL HTTP/gRPC implementation
- `unreal/Source/BodyBroker/Dialogue/FHttpDialogueRequest.h` - HTTP request wrapper
- `unreal/Source/BodyBroker/Dialogue/FGrpcDialogueRequest.h` - gRPC client (production)
- `unreal/Source/BodyBroker/Dialogue/FDialogueResponse.h` - Response parsing
- `unreal/Source/BodyBroker/UI/DialogueWidget.h` - UI widget for dialogue display
- `unreal/Source/BodyBroker/UI/DialogueWidget.cpp` - REAL UI implementation

**Integration (REAL):**
- REAL HTTP calls to `http://ai-inference:8000/v1/dialogue` (MVP)
- REAL gRPC calls to `ai-inference:50051` (Production)
- REAL streaming response handling
- REAL error handling and fallbacks

**Acceptance Criteria:**
- UE5 makes REAL HTTP calls to AI Inference Service
- Dialogue responses displayed in game
- Streaming responses update UI in real-time
- Error handling provides fallback dialogue
- **REAL TEST**: Run UE5 game, interact with NPC, verify HTTP call to real service, verify dialogue appears

---

### Task 5.3: Game Client Integration with Story Teller
**Task ID:** TBB-015  
**Dependencies:** TBB-014, TBB-012  
**Description:**  
Integrate UE5 game client with Story Teller service. Subscribe to REAL Kafka topics for world events, receive REAL Redis Pub/Sub updates, update game world dynamically.

**Deliverables:**
- `unreal/Source/BodyBroker/StoryTeller/FStoryTellerClient.h` - Story Teller client
- `unreal/Source/BodyBroker/StoryTeller/FStoryTellerClient.cpp` - REAL Kafka/Redis integration
- `unreal/Source/BodyBroker/StoryTeller/FKafkaSubscriber.h` - Kafka message consumer
- `unreal/Source/BodyBroker/StoryTeller/FRedisPubSub.h` - Redis Pub/Sub client
- `unreal/Source/BodyBroker/World/FWorldUpdateHandler.h` - World update processor

**Integration (REAL):**
- REAL Kafka consumer for `world.events.major` and `world.events.minor` topics
- REAL Redis Pub/Sub subscription to `world.updates` channel
- REAL world state updates applied to UE5 world

**Acceptance Criteria:**
- Game client subscribes to REAL Kafka topics
- Receives world events in real-time
- Updates game world dynamically based on events
- Handles connection failures gracefully
- **REAL TEST**: Run Story Teller, generate world event, verify UE5 client receives it via Kafka, verify world updates

---

## PHASE 6: LEARNING SERVICE

### Task 6.1: Learning Service - Model Improvement Pipeline
**Task ID:** TBB-016  
**Dependencies:** TBB-005, TBB-009  
**Description:**  
Implement Learning Service that receives feedback from game instances and improves models. Use REAL AWS SageMaker for training, REAL data pipelines.

**Deliverables:**
- `services/learning/server.py` - Learning service API
- `services/learning/feedback_collector.py` - Feedback collection from game
- `services/learning/data_pipeline.py` - REAL data processing pipeline
- `services/learning/sagemaker_training.py` - REAL SageMaker integration
- `services/learning/model_registry.py` - Model versioning and storage
- `services/learning/deployment_pipeline.py` - REAL CI/CD for model deployment
- `services/learning/quality_metrics.py` - Model quality evaluation

**Acceptance Criteria:**
- Collects REAL feedback from game instances
- Processes data through REAL pipeline
- Trains models on REAL SageMaker
- Deploys improved models via REAL CI/CD
- **REAL TEST**: Send feedback, verify pipeline processes it, verify SageMaker training job, verify model deployment

---

### Task 6.2: Model Deployment CI/CD
**Task ID:** TBB-017  
**Dependencies:** TBB-016  
**Description:**  
Implement automated model deployment pipeline. REAL GitHub Actions workflows, REAL SageMaker deployment, REAL testing before deployment.

**Deliverables:**
- `.github/workflows/model-deployment.yml` - REAL CI/CD workflow
- `services/learning/deployment/tests.py` - REAL model tests
- `services/learning/deployment/canary.py` - Canary deployment
- `services/learning/deployment/rollback.py` - Rollback automation

**Acceptance Criteria:**
- Model commits trigger REAL CI/CD pipeline
- Tests run against REAL models
- Canary deployment to 5% traffic
- Full rollout after validation
- **REAL TEST**: Push model update, verify CI/CD runs, verify canary deployment, verify full rollout

---

## PHASE 7: MODERATION & PAYMENT

### Task 7.1: Moderation Service - Content Filtering
**Task ID:** TBB-018  
**Dependencies:** TBB-004, TBB-007  
**Description:**  
Implement Moderation Service with REAL content filtering. Integrates with AI Inference Service via REAL middleware pattern. No mocked filtering.

**Deliverables:**
- `services/moderation/server.py` - Moderation service API
- `services/moderation/middleware.py` - REAL FastAPI middleware
- `services/moderation/text_filter.py` - Profanity/toxicity detection (REAL ML model)
- `services/moderation/content_analyzer.py` - AI content analysis
- `services/moderation/policy_enforcer.py` - Content policy rules

**Integration (REAL):**
- REAL middleware intercepts AI Inference responses
- REAL ML model calls for toxicity detection
- REAL fallback responses on timeout

**Acceptance Criteria:**
- Filters profanity from player inputs (REAL filtering, not mocked)
- Detects toxic content with >85% accuracy
- Integrates with AI Inference via REAL middleware
- **REAL TEST**: Send test content, verify filtering, verify toxicity detection, verify fallback

---

### Task 7.2: Payment Service - Stripe Integration
**Task ID:** TBB-019  
**Dependencies:** TBB-002  
**Description:**  
Implement Payment Service with REAL Stripe integration. Real payment processing, real webhook handling, real subscription management.

**Deliverables:**
- `services/payment/server.py` - Payment service API
- `services/payment/stripe_client.py` - REAL Stripe API client
- `services/payment/checkout.py` - REAL payment checkout flow
- `services/payment/webhook_handler.py` - REAL Stripe webhook processing
- `services/payment/subscription_manager.py` - REAL subscription handling
- `services/payment/coupon_system.py` - Ambassador coupon codes

**Integration (REAL):**
- REAL Stripe API calls (use test mode initially)
- REAL webhook verification
- REAL subscription creation/management
- REAL coupon code validation

**Acceptance Criteria:**
- Processes REAL test payments via Stripe
- Webhook verification implemented correctly
- Subscriptions created in REAL Stripe
- Coupon codes validated and applied
- **REAL TEST**: Create test payment, verify Stripe webhook received, verify subscription created, test coupon

---

## PHASE 8: INTEGRATION & TESTING

### Task 8.1: End-to-End Integration Testing
**Task ID:** TBB-020  
**Dependencies:** TBB-007, TBB-009, TBB-012, TBB-014, TBB-015  
**Description:**  
Test REAL integration between all services. Real HTTP/gRPC calls, real databases, real message buses. No mocked services.

**Deliverables:**
- `tests/integration/test_full_game_flow.py` - End-to-end game flow
- `tests/integration/test_story_teller_integration.py` - Story Teller integration tests
- `tests/integration/test_orchestration_workflows.py` - Orchestration workflow tests
- `tests/integration/test_payment_flow.py` - Payment integration tests
- `docker-compose.integration.yml` - REAL service deployment for testing

**Acceptance Criteria:**
- Tests run against REAL service instances
- All services communicate via REAL APIs
- Multi-service workflows execute successfully
- **REAL TEST**: Start all services, run integration tests, verify real communication, verify workflows

---

### Task 8.2: Performance & Load Testing
**Task ID:** TBB-021  
**Dependencies:** TBB-020  
**Description:**  
Conduct REAL load testing with actual traffic patterns. Real databases, real services, real load generators.

**Deliverables:**
- `tests/load/locustfile.py` - Locust load test scenarios
- `tests/load/k6_scripts.js` - K6 performance tests
- `tests/load/scenarios/game_flow.js` - Game flow load test
- `docs/performance_results.md` - REAL benchmark results
- `docs/optimization_recommendations.md` - Performance tuning guide

**Acceptance Criteria:**
- System handles 1000 concurrent users (REAL load test)
- 95th percentile response time <500ms (measured on REAL system)
- No memory leaks under sustained load
- **REAL TEST**: Run load tests against real services, measure metrics, verify targets met

---

## PHASE 9: DEPLOYMENT & OPERATIONS

### Task 9.1: Infrastructure Deployment
**Task ID:** TBB-022  
**Dependencies:** All service tasks  
**Description:**  
Deploy all services to REAL infrastructure (AWS, Kubernetes, etc.). Use REAL Terraform, REAL Kubernetes manifests, REAL deployment pipelines.

**Deliverables:**
- `terraform/main.tf` - REAL infrastructure definition
- `k8s/deployments/` - REAL Kubernetes manifests
- `.github/workflows/cd.yml` - REAL CI/CD pipeline
- `scripts/deploy.sh` - REAL deployment script

**Acceptance Criteria:**
- All services deployable to REAL Kubernetes
- Infrastructure created via REAL Terraform
- CI/CD pipeline deploys REAL services
- **REAL TEST**: Run Terraform, deploy to Kubernetes, verify services running, test deployment

---

## TASK COMPLETION CHECKLIST (MANDATORY)

For EVERY task completion:
- [ ] Memory consolidated to `.cursor/memory/project/`
- [ ] ALL tests run and passing (100% pass rate required)
- [ ] Next 45-minute milestone written
- [ ] Timer active and showing status
- [ ] Work visible in session window
- [ ] No fake/mock code implemented
- [ ] Real service integrations verified
- [ ] Git commit and push to GitHub
- [ ] Status updated in `TASK-STATUS.md`

---

**Central Log Location**: `.cursor/logs/session-{timestamp}.log`  
**Manager Log**: `.cursor/logs/manager.log`  
**Status File**: `.cursor/memory/active/TASK-STATUS.md`  
**Enforcement**: ALL rules in `/all-rules` are MANDATORY for every task

